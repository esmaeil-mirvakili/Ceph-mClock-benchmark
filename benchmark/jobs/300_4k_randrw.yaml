cluster:
  user: 'root'
  head: "client0"
  clients: ["client0"]
  osds: ["osd0", "osd1", "osd2", "osd3"]
  mons:
    osd0:
      a: "10.10.1.1:6789"
#  use_existing: False
  osds_per_node: 1
  iterations: 1
  conf_file: "/etc/ceph/ceph.conf"
  tmp_dir: "/tmp/cbt"
  ceph-osd_cmd: "ceph-osd"
  ceph-mon_cmd: "ceph-mon"
  ceph-run_cmd: "ceph-run"
  rados_cmd: "rados"
  ceph_cmd: "ceph"
  rbd_cmd: "rbd"
  clusterid: "ceph"
  replication: 3
  pool_profiles:
    rbd:
      pg_size: 8192
      pgp_size: 8192
      replication: 3
  recovery_test:
    osds: [1]

benchmarks:
  librbdfio:
      iterations: 1
      clientname: admin
      time: 300
      iodepth: [32]
      numjobs: 100000
      mode: [randrw]
      ioengine: libaio
      rwmixread: 50
      op_size: [4096]
      vol_size: 10240
      direct: 1
      use_dir: True
      output-format: json
      fio_cmd: 'fio'
      pool_profile: 'rbd'
      poolname: 'test_client_pool'
      recov_pool_name: 'test_recovery_pool'
      rbdname: 'img01'
      use_existing_volumes: False
